<html>

<head>
    <title>RAVEN: A Dataset for Relational and Analogical Visual rEasoNing</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="About Machine Learning, Computer Vision, Life, Photo Gallery and Everything | Chi Zhang, Programmer, Machine Learning and Computer Vision">
    <meta name="keyword"  content="Chi Zhang, 张驰, Vikat的男朋友, Blog, Internet, Machine Learning, Computer Vision">
    <link rel="shortcut icon" href="/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/css/project.css"">
</head>

<body>

<div id="Banner">
    <div height="80" id="header" style="background-color:#FFFFFF; color: #FFFFFF">
        <center>
            <table width="1200" height="80" border="0">
                <tr>
                    <td halign="center">
                        <p class=un>RAVEN: A Dataset for <u>R</u>elational and <u>A</u>nalogical <u>V</u>isual r<u>E</u>aso<u>N</u>ing</p>
                        <hr>
                    </td>
                </tr>
            </table>
        </center>
    </div>
</div>

<div id="main" style="padding-bottom:1em; padding-top: 2em; width: 70em; max-width: 70em; margin-left: auto; margin-right: auto;">
    <center>
        <img src="/img/in-post/RAVEN/process.jpg" style="width: 100%;">
    </center>
    <br>
    <heading>
        Abstract
    </heading>
    <p>
        Dramatic progress has been witnessed in basic vision tasks involving low-level perception, such as object recognition, detection, and tracking. Unfortunately, there is still an enormous performance gap between artificial vision systems and human intelligence in terms of higher-level vision problems, especially ones involving reasoning. Earlier attempts in equipping machines with high-level reasoning have hovered around Visual Question Answering (VQA), one typical task associating vision and language understanding. In this work, we propose a new dataset, built in the context of Raven's Progressive Matrices (RPM) and aimed at lifting machine intelligence by associating vision with structural, relational, and analogical reasoning in a hierarchical representation. Unlike previous works in measuring abstract reasoning using RPM, we establish a semantic link between vision and reasoning by providing structure representation. This addition enables a new type of abstract reasoning by jointly operating on the structure representation. Machine reasoning ability using modern computer vision is evaluated in this newly proposed dataset. Additionally, we also provide human performance as a reference. Finally, we show consistent improvement across all models by incorporating a simple neural module that combines visual understanding and structure reasoning.
    </p>
</div>

<div id="main" style="padding-bottom:0em; padding-top: 0em; width: 70em; max-width: 70em; margin-left: auto; margin-right: auto;">
    <heading>
        Paper
    </heading>
    <p>
        <papertitle>RAVEN: A Dataset for <u>R</u>elational and <u>A</u>nalogical <u>V</u>isual r<u>E</u>aso<u>N</u>ing</papertitle><br>
                    Chi Zhang<sup>*</sup>, Feng Gao<sup>*</sup>, Baoxiong Jia, Yixin Zhu, Song-Chun Zhu<br>
                    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019<br>
                    (<sup>*</sup> indicates equal contribution.)<br>
                    <a href="/attach/cvpr19zhang.pdf">Paper</a> /
                    <a href="/attach/cvpr19zhang_supp.pdf">Supplementary</a> /
                    <a href="https://github.com/WellyZhang/RAVEN">Code</a> /
                    <a href="/blog/2019/03/07/RAVEN">Blog</a>
    </p>
    <p>
        <center>
            <a href="/attach/cvpr19zhang.pdf"><img src="/img/project/raven_thumbnail.jpg" style="width: 100%;"/></a>
        </center>
    </p>
</div>

<div id="main" style="padding-bottom:0em; padding-top: 2em; width: 70em; max-width: 70em; margin-left: auto; margin-right: auto; align-content: center">
	<heading>
        Team
    </heading>
	<div style="text-align: center; width: 100%; padding-top: 1em">
		<div style="display: inline-block; width: 180px;">
			<a href="http://wellyzhang.github.com">
				<img src="http://vcla.stat.ucla.edu/images/people/chiz.jpg" alt="" style="border-radius: 50%; width:150px;">
				<p>Chi Zhang<sup>1,2</sup></p>
			</a>
        </div>
        <div style="display: inline-block; width: 180px;">
			<a href="https://fen9.github.io/"><img src="http://vcla.stat.ucla.edu/images/people/fgao.jpg" alt="" style="border-radius: 50%; width:150px;">
			    <p>Feng Gao<sup>1,2</sup></p>
			</a>
        </div>
        <div style="display: inline-block; width: 180px;">
			<a href="https://buzz-beater.github.io/"><img src="http://vcla.stat.ucla.edu/images/people/bxjia.jpg" alt="" style="border-radius: 50%; width:150px;">
			    <p>Baoxiong Jia<sup>1</sup></p>
			</a>
		</div>
		<div style="display: inline-block; width: 180px;">
			<a href="http://www.yzhu.io/"><img src="http://siyuanhuang.com/cooperative_parsing/yzhu.jpg" alt="" style="border-radius: 50%; width:150px;">
			    <p>Yixin Zhu<sup>1,2</sup></p>
			</a>
		</div>
		<div style="display: inline-block; width: 180px;">
			<a href="http://www.stat.ucla.edu/~sczhu/"><img src="http://vcla.stat.ucla.edu/images/people/Zhu_UCLA.JPG" alt="" style="border-radius: 50%; width:150px;">
			    <p>Song-Chun Zhu<sup>1,2</sup></p>
			</a>
		</div>
	</div>
	<div style="text-align:center; width: 100%;">
        <div style="display: inline-block; width: 500px;">
			<p><sup>1 </sup>UCLA Center for Vision, Cognition, Learning and Autonomy</p>
        </div>
        <div style="display: inline-block; width: 500px;">
			<p><sup>2 </sup>International Center for AI and Robot Autonomy (CARA)</p>
        </div>
	</div>
</div>

<div id="main" style="padding-bottom:1em; padding-top: 0em; width: 80em; max-width: 70em; margin-left: auto; margin-right: auto;">
    <heading id="dataset">
        Dataset
    </heading>
    <p>
        Download RAVEN-10000 <a href="https://drive.google.com/file/d/111swnEzAY2NfZgeyAhVwQujMjRUfeyuY/view?usp=sharing">here</a>: there are 10,000 problems for each figure configuration. Check our <a href="https://github.com/WellyZhang/RAVEN/tree/master/assets">GitHub</a> for dataset organization.
    </p>
    <p>
        The dataset is generated using Attributed Stochastic Image Grammar. 
        <br>
        <center>
            <img src="/img/in-post/RAVEN/prologue.jpg" style="width: 50%;">
        </center>
    </p>
    <p>
        In total, we have 7 configurations.
        <br>
        <center>
            <img src="/img/in-post/RAVEN/peek_view.png" style="width: 80%;">
        </center>
    </p>
    <p>
        Try it yourself!
        <br>
        <center>
            <img src="/img/in-post/RAVEN/noise_attr.png" style="width: 50%;">
        </center>
    </p>
</div>

<div id="main" style="padding-bottom:1em; padding-top: 0em; width: 80em; max-width: 70em; margin-left: auto; margin-right: auto;">
    <heading>
        Code
    </heading>
    <p>
        View on <a href="https://github.com/WellyZhang/RAVEN">GitHub</a>
    </p>
</div>

<div id="main" style="padding-bottom:1em; padding-top: 0em; width: 80em; max-width: 70em; margin-left: auto; margin-right: auto;">
    <heading>
        Bibtex
    </heading>
    <p class=bibtax>
        @inproceedings{zhang2019raven,
        <br>author={Zhang, Chi and Gao, Feng and Jia, Baoxiong and Zhu, Yixin and Zhu, Song-Chun},
        <br>title={RAVEN: A Dataset for Relational and Analogical Visual rEasoNing},
        <br>booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        <br>year={2019}}
    </p>
</div>

</body>

</html>
