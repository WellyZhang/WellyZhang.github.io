---
layout: page
title: About Me
description: "Hi, I'm Chi Zhang (张驰)."
header-img: "img/banner/about-banner.jpg"
---

<div class="post-container">

<blockquote>
  <p>"The study of vision must therefore include not only the study of how to extract from images the various aspects of the world that are useful to us, but also an inquiry into the nature of the <strong>internal reprensentations</strong> by which we capture this information and thus make it available as a <strong>basis</strong> for decisions about our thoughts and actions." &#8208 David Marr</p>
</blockquote>

<p><font color="red">News!</font> Two papers accepted in CVPR 2021.
<p><font color="red">News!</font> One paper accpeted in ICRA 2021.
<p><font color="red">News!</font> Our position paper featured in Engineering.
<p><font color="red">News!</font> One paper accepted as Oral in AAAI 2020.
<p><font color="red">News!</font> One paper accepted as Spotlight in NeurIPS 2019.
<p><font color="red">News!</font> One paper accepted in IROS 2019.
<p><font color="red">News!</font> One paper accepted in CVPR 2019.
<p><font color="red">News!</font> Two papers accepted in AAAI 2019.
</p>

<h2 id="about-me">About Me</h2>

<p>I’m Chi Zhang (张驰)– a Ph.D. candidate of <em>Department of Computer Science, University of California - Los Angeles</em>. I’m a graduate student researcher at <em>Center for Vision, Cognition, Learning and Autonomy (VCLA)</em>, advised by <a href="http://www.stat.ucla.edu/~sczhu/">Professor Song-Chun Zhu</a>.</p>

<p>My reseach interests include but are not limited to</p>

<ul>
  <li>Computer Vision: Visual Reasoning, Abstract Reasoning</li>
  <li>Machine Learning: Neural-Symbolic Methods, Concept Learning, Reinforcement Learning</li>
</ul>

<p>I used to work with <a href="https://home.cse.ust.hk/~dyyeung/www/Home.html">Professor Dit-Yan Yeung</a> at <em>Hong Kong University of Science and Technology</em> and <a href="http://www.cad.zju.edu.cn/home/dengcai/">Professor Deng Cai</a> at my home institution, <em>Zhejiang University</em>.</p>

<p>I serve/served as</p>
<ul>
  <li>Conference reviewer: CVPR 2019, ICCV 2019, AAAI 2020, CVPR 2020, ECCV 2020, NeurIPS 2020, AAAI 2021, ICLR 2021, CVPR 2021, ICCV 2021, ICML 2021</li>
  <li>Journal reviewer: IEEE Transactions on Image Processing (TIP)</li>
</ul>

<p><a href="/attach/CV_eng_blog.pdf">CV</a> / <a href="mailto:wellyzhangc@gmail.com">Email</a></p>

<h2 id="publications">Publications</h2>

<div class="pub-img">
    <ul>
        <li>
          <img src="./img/about/papers/cvpr21zhang_acre.png" class="thumbnail">
          <div class="title">ACRE: <u>A</u>bstract <u>C</u>ausal <u>RE</u>asoning Beyond Covariation</div>
          <div class="authors"><strong>Chi Zhang</strong>, Baoxiong Jia, Mark Edmonds, Song-Chun Zhu, Yixin Zhu</div>
          <div class="venue"><strong>CVPR 2021</strong></div>
        </li>
        <hr>
        <li>
          <img src="./img/about/papers/cvpr21zhang_prae.png" class="thumbnail">
          <div class="title">Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution</div>
          <div class="authors"><strong>Chi Zhang</strong><a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Baoxiong Jia<a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Song-Chun Zhu, Yixin Zhu</div>
          <div class="venue"><strong>CVPR 2021</strong></div>
          <div class="resources">
            <a href="./attach/cvpr21zhang_prae.pdf">Paper</a> /
            <a href="./attach/cvpr21zhang_prae_supp.pdf">Supp</a> /
            <a href="https://github.com/WellyZhang/PrAE">Code</a> /
            <a href="./project/prae.html">Project</a>
          </div>
        </li>
        <hr>
        <li>
          <img src="./img/about/papers/icra21xie.png" class="thumbnail">
          <div class="title">Congestion-aware Multi-agent Trajectory Prediction for Collision Avoidance</div>
          <div class="authors">Xu Xie, <strong>Chi Zhang</strong>, Yixin Zhu, Ying Nian Wu, Song-Chun Zhu</div>
          <div class="venue"><strong>ICRA 2021</strong></div>
        </li>
        <hr>
        <li>
          <img src="./img/about/papers/dark.png" class="thumbnail">
          <div class="title">Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense</div>
          <div class="authors">Yixin Zhu, Tao Gao, Lifeng Fan, Siyuan Huang, Mark Edmonds, Hangxin Liu, Feng Gao, <strong>Chi Zhang</strong>, Siyuan Qi, Ying Nian Wu, Joshua B. Tenenbaum, Song-Chun Zhu</div>
          <div class="venue"><strong>Engineering, Volume 6, Issue 3</strong></div>
          <div class="resources">
              <a href="./attach/dark.pdf">Paper</a> /
              <a href="https://www.sciencedirect.com/science/article/pii/S2095809920300345">Link</a>
          </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/aaai2020zhang.png" class="thumbnail">
            <div class="title">Machine Number Sense: A Dataset of Visual Arithmetic Problems for Abstract and Relational Reasoning</div>
            <div class="authors">Wenhe Zhang, <strong>Chi Zhang</strong>, Yixin Zhu, Song-Chun Zhu</div>
            <div class="venue"><strong>AAAI 2020</strong></div>
            <div class="venue"><font color="red">Oral</font></div>
            <div class="resources">
                <a href="./attach/aaai20zhang.pdf">Paper</a> /
                <a href="./attach/aaai20zhang_poster.pdf">Poster</a> /
                <a href="https://github.com/zwh1999anne/Machine-Number-Sense-Dataset">Code</a> /
                <a href="https://drive.google.com/file/d/17KuL8KOIDAeRL-lD418oiDEm8bE6TEFb/view">Dataset</a> /
                <a href="https://sites.google.com/view/number-sense/home">Project</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/neurips2019zhang.jpg" class="thumbnail">
            <div class="title">Learning Perceptual Inference by Contrasting</div>
            <div class="authors"><strong>Chi Zhang</strong><a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Baoxiong Jia<a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Feng Gao, Yixin Zhu, Hongjing Lu, Song-Chun Zhu</div>
            <div class="venue"><strong>NeurIPS 2019</strong></div>
            <div class="venue"><font color="red">Spotlight</font> (2.43% acceptance rate)</div>
            <div class="resources">
                <a href="./attach/neurips19zhang.pdf">Paper</a> /
                <a href="./attach/neurips19slides.pdf">Slides</a> /
                <a href="./attach/neurips19poster.pdf">Poster</a> /
                <a href="https://github.com/WellyZhang/CoPINet">Code</a> /
                <a href="./blog/2019/11/25/CoPINet">Blog</a> /
                <a href="./project/copinet.html">Project</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="https://xuxie1031.github.io/resources/iros19.png" class="thumbnail">
            <div class="title">Learning Virtual Grasp with Failed Demonstrations via Bayesian Inverse Reinforcement Learning</div>
            <div class="authors">Xu Xie<a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Changyang Li<a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, <strong>Chi Zhang</strong>, Yixin Zhu, Song-Chun Zhu</div>
            <div class="venue"><strong>IROS 2019</strong></div> 
            <div class="resources">
                <a href="https://xuxie1031.github.io/resources/iros19xie.pdf">Paper</a> /
                <a href="https://vimeo.com/350872475">Demo</a> /
                <a href="https://github.com/xuxie1031/VRGraspIRLEnv">Code</a> /
                <a href="https://xuxie1031.github.io/projects/VRGrasp/VRGraspProj.html">Project</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/cvpr19zhang.jpg" class="thumbnail">
            <div class="title">RAVEN: A Dataset for <u>R</u>elational and <u>A</u>nalogical <u>V</u>isual r<u>E</u>aso<u>N</u>ing</div>
            <div class="authors"><strong>Chi Zhang</strong><a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Feng Gao<a data-toggle="tooltip" title="Equal contribution"><sup>*</sup></a>, Baoxiong Jia, Yixin Zhu, Song-Chun Zhu</div>
            <div class="venue"><strong>CVPR 2019</strong></div> 
            <div class="resources">
                <a href="./attach/cvpr19zhang.pdf">Paper</a> /
                <a href="./attach/cvpr19zhang_supp.pdf">Supp</a> /
                <a href="./attach/cvpr19poster.pdf">Poster</a> /
                <a href="https://github.com/WellyZhang/RAVEN">Code</a> /
                <a href="./project/raven.html#dataset">Dataset</a> /
                <a href="./blog/2019/03/07/RAVEN">Blog</a> /
                <a href="./project/raven.html">Project</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/aaai19zhang.png" class="thumbnail">
            <div class="title">MetaStyle: Three-Way Trade-Off Among Speed, Flexibility, and Quality in Neural Style Transfer</div>
            <div class="authors"><strong>Chi Zhang</strong>, Yixin Zhu, Song-Chun Zhu</div>
            <div class="venue"><strong>AAAI 2019</strong></div> 
            <div class="resources">
                <a href="./attach/aaai19zhang.pdf">Paper</a> /
                <a href="./attach/aaai19zhang_supp.pdf">Supp</a> /
                <a href="./attach/aaai19slides.pdf">Slides</a> /
                <a href="./attach/aaai19poster.pdf">Poster</a> /
                <a href="https://vimeo.com/303954291">Demo</a> /
                <a href="https://github.com/WellyZhang/MetaStyle">Code</a> /
                <a href="./blog/2018/12/06/MetaStyle">Blog</a> /
                <a href="./project/metastyle.html">Project</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/aaai19liu.png" class="thumbnail">
            <div class="title">Mirroring without Overimitation: Learning Functionally Equivalent Manipulation Actions</div>
            <div class="authors">Hangxin Liu, <strong>Chi Zhang</strong>, Yixin Zhu, Chenfanfu Jiang, Song-Chun Zhu</div>
            <div class="venue"><strong>AAAI 2019</strong></div> 
            <div class="resources">
                <a href="./attach/aaai19liu.pdf">Paper</a> /
                <a href="./blog/2018/12/04/mirroring">Blog</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/IJCAI18.png" class="thumbnail">
            <div class="title">Learning Unmanned Aerial Vehicle Control for Autonomous Target Following</div>
            <div class="authors">Siyi Li, Tianbo Liu, <strong>Chi Zhang</strong>, Dit-Yan Yeung, Shaojie Shen</div>
            <div class="venue"><strong>IJCAI 2018</strong></div> 
            <div class="resources">
                <a href="https://www.ijcai.org/proceedings/2018/0685.pdf">Paper</a> /
                <a href="./blog/2018/11/26/quadrotor-tracking">Blog</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/Neurocomputing.png" class="thumbnail">
            <div class="title">Question Retrieval for Community-based Question Answering via Heterogeneous Social Influential Network</div>
            <div class="authors">Zheqian Chen, <strong>Chi Zhang</strong>, Zhou Zhao, Chengwei Yao, Deng Cai</div>
            <div class="venue"><strong>Neurocomputing, Volume 285</strong></div>
            <div class="resources">
                <a href="https://www.sciencedirect.com/science/article/pii/S0925231218300523">Paper</a> /
                <a href="./blog/2018/11/26/CQA">Blog</a>
            </div>
        </li>
        <hr>
        <li>
            <img src="./img/about/papers/Patent.png" class="thumbnail">
            <div class="title">A Method of Exact 3D Modeling Based on Natural Gestures via Data Gloves (in Chinese)</div>
            <div class="authors">Xiangdong Li, Sihong Lv, Yikun Wang, Xiaowo Sun, <strong>Chi Zhang</strong></div>
            <div class="venue"><strong>Patent publication number: CN104778746 B</strong></div>
            <div class="resources">
                <a href="https://www.google.com/patents/CN104778746B">Link</a>
            </div>
        </li>
    </ul>
</div>

<h2 id="experience">Education</h2>

<div class="exp-proj">
  <ul>
    <li>
      <img src="./img/about/experience/UCLA_logo.png">
      <h4>Ph.D. in Computer Science</h4>
      <h4>
        <small>09.2017 - Summer 2022 (expected) | Los Angeles, California, USA</small>
      </h4>
      <h5>University of California, Los Angeles</h5>
    </li>
    <li>
      <img src="./img/about/experience/UCLA_logo.png">
      <h4>Master of Science in Computer Science</h4>
      <h4>
        <small>09.2017 - 03.2019 | Los Angeles, California, USA</small>
      </h4>
      <h5>University of California, Los Angeles</h5>
    </li>
    <li>
      <img src="./img/about/experience/ZJU_logo.png">
      <h4>Bachelor of Engineering in Computer Science</h4>
      <h4>
        <small>09.2013 - 06.2017 | Hangzhou, Zhejiang, China</small>
      </h4>
      <h5>Zhejiang University</h5>
    </li>
  </ul>
</div>

<h2 id="experience">Experience</h2>

<div class="exp-proj">
  <ul>
    <li>
      <img src="./img/about/experience/Didi_logo.png">
      <h4>Machine Learning Engineer</h4>
      <h4>
        <small>Autonomous driving</small>
        <br>
        <small>04.2017 - 06.2017 | Hangzhou, Zhejiang, China</small>
      </h4>
      <h5>Didi Research Institute</h5>
    </li>
    <li>
        <img src="./img/about/experience/HKUST_logo.png">
        <h4>Research Intern</h4>
        <h4>
          <small>Target following with drones</small>
          <br>
          <small>09.2016 - 03.2017 | Clear Water Bay, Kowloon, Hong Kong</small>
        </h4>
        <h5>Hong Kong University of Science and Technology</h5>
      </li>
    <li>
        <img src="./img/about/experience/ZJU_logo.png">
        <h4>Research Assistant</h4>
        <h4>
          <small>Automatic number plate detection</small>
          <br>
          <small>03.2015 - 06.2016 | Hangzhou, Zhejiang, China</small>
        </h4>
        <h5>State Key Lab of CAD &amp; CG, Zhejiang University</h5>
      </li>
  </ul>
</div>

<h2 id="projects">Projects</h2>

<div class="exp-proj">
  <ul>
    <li>
      <img src="./img/about/projects/mxnet_logo.png">
      <h4>MXNet</h4>
      <h4>
        <small>09.2016 - 04.2017</small>
      </h4>
    </li>
    <li>
      <img src="./img/about/projects/Darknet_logo.png">
      <h4>Automatic Number Plate Detection</h4>
      <h4>
        <small>03.2015 - 06.2016</small>
      </h4>
    </li>
  </ul>
</div>

<!-- <h2 id="presentations">Presentations</h2>

<ul>
  <li><a href="/attach/Detection_as_Regression.pdf">Detection as Regression</a></li>
  <li><a href="/attach/Post-ANPR.pdf">Real-Time Automatic Number Plate Detection</a></li>
</ul> -->

</div>
